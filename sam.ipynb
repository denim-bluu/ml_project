{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(np.number)\n",
    "scaled_features = StandardScaler().fit_transform(numeric_df.values)\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=numeric_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df.select_dtypes(exclude=np.number)\n",
    "dummy_df = pd.get_dummies(\n",
    "    cat_df, drop_first=True\n",
    ")  # Drop first dummy variable as a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([scaled_df, dummy_df], axis=1)\n",
    "features[\"HeartDisease\"] = df[\n",
    "    \"HeartDisease\"\n",
    "]  # Undo standard scaling for target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.drop(columns=[\"HeartDisease\"])\n",
    "y = features[\"HeartDisease\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant Analysis (LDA/QDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "# Start with solver\n",
    "grid = {'solver': ['svd', 'lsqr', 'eigen']}\n",
    "\n",
    "lda_mod = LinearDiscriminantAnalysis()\n",
    "clf = GridSearchCV(lda_mod, param_grid=grid, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "best_lda = clf.fit(X_train, y_train)\n",
    "\n",
    "# SVD is best solver, so no shrinkage tuning required\n",
    "print(best_lda.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       109\n",
      "           1       0.93      0.87      0.90       167\n",
      "\n",
      "    accuracy                           0.88       276\n",
      "   macro avg       0.88      0.89      0.88       276\n",
      "weighted avg       0.89      0.88      0.88       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall = [.9, .87], weighted avg = .88\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       109\n",
      "           1       0.93      0.85      0.89       167\n",
      "\n",
      "    accuracy                           0.87       276\n",
      "   macro avg       0.87      0.88      0.87       276\n",
      "weighted avg       0.88      0.87      0.87       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QDA\n",
    "qda_mod = QuadraticDiscriminantAnalysis()\n",
    "qda_mod.fit(X_train, y_train)\n",
    "\n",
    "# recall = [.91, .85], weighted avg = .87\n",
    "y_pred = qda_mod.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 689 tasks      | elapsed:   25.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   26.3s finished\n",
      "/Users/sam/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_mod = SVC()\n",
    "\n",
    "grid = {\n",
    "    'C': [.01, .1, 1, 10],\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['auto', 10, 1, .1, .01, .001]\n",
    "}\n",
    "\n",
    "# grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "clf_svm = GridSearchCV(svm_mod, param_grid=grid, scoring='roc_auc', cv=10, n_jobs=-1, verbose=2)\n",
    "best_svm = clf_svm.fit(X_train, y_train)\n",
    "print(best_svm.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       109\n",
      "           1       0.91      0.89      0.90       167\n",
      "\n",
      "    accuracy                           0.88       276\n",
      "   macro avg       0.87      0.88      0.88       276\n",
      "weighted avg       0.88      0.88      0.88       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.7999999999999999, 'gamma': 0.5, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 1.0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 0.7999999999999999, 'verbosity': 1, 'eta': 0.05}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb_mod = XGBClassifier()\n",
    "\n",
    "dist = {\n",
    "        'eta': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0, 0.1, 0.5, 1.0, 5, 10],\n",
    "        'subsample': np.arange(0.5, 1, 0.1),\n",
    "        'colsample_bytree': np.arange(0.5, 1, 0.1),\n",
    "        'max_depth': np.arange(3, 10, 2),\n",
    "        'scale_pos_weight': [1, 1.2],\n",
    "        'reg_alpha': [0, 0.1, 1.0, 10.0, 100.0],\n",
    "        'reg_lambda': [0, 0.1, 1.0, 10.0, 100.0]\n",
    "        }\n",
    "\n",
    "clf_xgb = RandomizedSearchCV(xgb_mod, param_distributions=dist, scoring='roc_auc', n_iter=50, cv=10, random_state=1, n_jobs=-1, verbose=2)\n",
    "best_xgb = clf_xgb.fit(X_train, y_train)\n",
    "print(best_xgb.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       109\n",
      "           1       0.92      0.87      0.90       167\n",
      "\n",
      "    accuracy                           0.88       276\n",
      "   macro avg       0.87      0.88      0.88       276\n",
      "weighted avg       0.88      0.88      0.88       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# recall = [.85, .93], weighted avg = .90\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
